{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bible Text Preprocessing\n",
    "This notebook loads the KJV Bible text and creates a structured DataFrame, and create embeddings.\n",
    "Embeddings saved as csv and chromadb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:02:35.191389Z",
     "iopub.status.busy": "2025-01-07T05:02:35.191080Z",
     "iopub.status.idle": "2025-01-07T05:02:39.948899Z",
     "shell.execute_reply": "2025-01-07T05:02:39.948567Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#for creating embeddings\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "import chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:02:39.951369Z",
     "iopub.status.busy": "2025-01-07T05:02:39.950612Z",
     "iopub.status.idle": "2025-01-07T05:02:40.019887Z",
     "shell.execute_reply": "2025-01-07T05:02:40.019536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total verses: 31102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heaven and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>And the earth was without form, and void; and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>And God said, Let there be light: and there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>And God saw the light, that [it was] good: and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>And God called the light Day, and the darkness...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book  chapter  verse                                               text\n",
       "0  Genesis        1      1  In the beginning God created the heaven and th...\n",
       "1  Genesis        1      2  And the earth was without form, and void; and ...\n",
       "2  Genesis        1      3  And God said, Let there be light: and there wa...\n",
       "3  Genesis        1      4  And God saw the light, that [it was] good: and...\n",
       "4  Genesis        1      5  And God called the light Day, and the darkness..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the KJV Bible text file\n",
    "with open('assets/bible/kjv.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Skip the header lines (first two lines)\n",
    "bible_lines = lines[2:]\n",
    "\n",
    "# Initialize lists to store the components\n",
    "books = []\n",
    "chapters = []\n",
    "verses = []\n",
    "texts = []\n",
    "\n",
    "# Process each line\n",
    "for line in bible_lines:\n",
    "    \n",
    "    # Split the reference from the text\n",
    "    reference, text = line.strip().split('\\t')\n",
    "\n",
    "    # Split the reference into book, chapter, and verse\n",
    "    book = ' '.join(reference.split()[:-1])  # Everything except the last part\n",
    "    chapter_verse = reference.split()[-1]    # Last part (chapter:verse)\n",
    "    chapter, verse = chapter_verse.split(':')\n",
    "    \n",
    "    # Append to respective lists\n",
    "    books.append(book)\n",
    "    chapters.append(int(chapter))\n",
    "    verses.append(int(verse))\n",
    "    texts.append(text)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'book': books,\n",
    "    'chapter': chapters,\n",
    "    'verse': verses,\n",
    "    'text': texts\n",
    "})\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Total verses: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T05:02:40.047257Z",
     "iopub.status.busy": "2025-01-07T05:02:40.047080Z",
     "iopub.status.idle": "2025-01-07T05:02:40.059457Z",
     "shell.execute_reply": "2025-01-07T05:02:40.058963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total books: 66\n",
      "Total chapters: 1189\n",
      "Total verses: 31102\n",
      "\n",
      "Detailed breakdown:\n",
      "              book chapter verse        \n",
      "                           count min max\n",
      "0     1 Chronicles       1    54   1  54\n",
      "1     1 Chronicles       2    55   1  55\n",
      "2     1 Chronicles       3    24   1  24\n",
      "3     1 Chronicles       4    43   1  43\n",
      "4     1 Chronicles       5    26   1  26\n",
      "...            ...     ...   ...  ..  ..\n",
      "1184     Zechariah      13     9   1   9\n",
      "1185     Zechariah      14    21   1  21\n",
      "1186     Zephaniah       1    18   1  18\n",
      "1187     Zephaniah       2    15   1  15\n",
      "1188     Zephaniah       3    20   1  20\n",
      "\n",
      "[1189 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Counts\n",
    "total_books = df['book'].nunique()\n",
    "total_chapters = df.groupby(['book', 'chapter']).size().shape[0]\n",
    "total_verses = len(df)\n",
    "\n",
    "print(f\"Total books: {total_books}\")\n",
    "print(f\"Total chapters: {total_chapters}\")\n",
    "print(f\"Total verses: {total_verses}\")\n",
    "\n",
    "# For a detailed breakdown:\n",
    "print(\"\\nDetailed breakdown:\")\n",
    "breakdown = df.groupby(['book', 'chapter']).agg({\n",
    "    'verse': ['count', 'min', 'max']\n",
    "}).reset_index()\n",
    "print(breakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 31102 remaining verses in 312 batches...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304c82f2b5ad4b7eb6114487fc9be8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generation complete!\n",
      "Adding to ChromaDB...\n",
      "Added 1533 verses from Genesis\n",
      "Added 1213 verses from Exodus\n",
      "Added 859 verses from Leviticus\n",
      "Added 1288 verses from Numbers\n",
      "Added 959 verses from Deuteronomy\n",
      "Added 658 verses from Joshua\n",
      "Added 618 verses from Judges\n",
      "Added 85 verses from Ruth\n",
      "Added 810 verses from 1 Samuel\n",
      "Added 695 verses from 2 Samuel\n",
      "Added 816 verses from 1 Kings\n",
      "Added 719 verses from 2 Kings\n",
      "Added 942 verses from 1 Chronicles\n",
      "Added 822 verses from 2 Chronicles\n",
      "Added 280 verses from Ezra\n",
      "Added 406 verses from Nehemiah\n",
      "Added 167 verses from Esther\n",
      "Added 1070 verses from Job\n",
      "Added 2461 verses from Psalm\n",
      "Added 915 verses from Proverbs\n",
      "Added 222 verses from Ecclesiastes\n",
      "Added 117 verses from Song of Solomon\n",
      "Added 1292 verses from Isaiah\n",
      "Added 1364 verses from Jeremiah\n",
      "Added 154 verses from Lamentations\n",
      "Added 1273 verses from Ezekiel\n",
      "Added 357 verses from Daniel\n",
      "Added 197 verses from Hosea\n",
      "Added 73 verses from Joel\n",
      "Added 146 verses from Amos\n",
      "Added 21 verses from Obadiah\n",
      "Added 48 verses from Jonah\n",
      "Added 105 verses from Micah\n",
      "Added 47 verses from Nahum\n",
      "Added 56 verses from Habakkuk\n",
      "Added 53 verses from Zephaniah\n",
      "Added 38 verses from Haggai\n",
      "Added 211 verses from Zechariah\n",
      "Added 55 verses from Malachi\n",
      "Added 1071 verses from Matthew\n",
      "Added 678 verses from Mark\n",
      "Added 1151 verses from Luke\n",
      "Added 879 verses from John\n",
      "Added 1007 verses from Acts\n",
      "Added 433 verses from Romans\n",
      "Added 437 verses from 1 Corinthians\n",
      "Added 257 verses from 2 Corinthians\n",
      "Added 149 verses from Galatians\n",
      "Added 155 verses from Ephesians\n",
      "Added 104 verses from Philippians\n",
      "Added 95 verses from Colossians\n",
      "Added 89 verses from 1 Thessalonians\n",
      "Added 47 verses from 2 Thessalonians\n",
      "Added 113 verses from 1 Timothy\n",
      "Added 83 verses from 2 Timothy\n",
      "Added 46 verses from Titus\n",
      "Added 25 verses from Philemon\n",
      "Added 303 verses from Hebrews\n",
      "Added 108 verses from James\n",
      "Added 105 verses from 1 Peter\n",
      "Added 61 verses from 2 Peter\n",
      "Added 105 verses from 1 John\n",
      "Added 13 verses from 2 John\n",
      "Added 14 verses from 3 John\n",
      "Added 25 verses from Jude\n",
      "Added 404 verses from Revelation\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "def save_checkpoint(checkpoint_file: str, last_processed_idx: int, completed_books: list):\n",
    "    \"\"\"Save progress checkpoint\"\"\"\n",
    "    with open(checkpoint_file, 'w') as f:\n",
    "        json.dump({\n",
    "            'last_processed_idx': last_processed_idx,\n",
    "            'completed_books': completed_books\n",
    "        }, f)\n",
    "\n",
    "def load_checkpoint(checkpoint_file: str):\n",
    "    \"\"\"Load progress from checkpoint\"\"\"\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {'last_processed_idx': 0, 'completed_books': []}\n",
    "\n",
    "def process_verses_with_resume(\n",
    "    df: pd.DataFrame, \n",
    "    embeddings_model: OpenAIEmbeddings,\n",
    "    batch_size: int = 100,\n",
    "    csv_path: str = 'assets/bible/kjv_embeddings.csv',\n",
    "    persist_directory: str = 'assets/bible/chromadb',\n",
    "    checkpoint_file: str = 'assets/bible/embedding_checkpoint.json'\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Process Bible verse embeddings with failure recovery.\n",
    "    \"\"\"\n",
    "    # Create directories\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    \n",
    "    # Load checkpoint if exists\n",
    "    checkpoint = load_checkpoint(checkpoint_file)\n",
    "    start_idx = checkpoint['last_processed_idx']\n",
    "    completed_books = set(checkpoint['completed_books'])\n",
    "    \n",
    "    # Load existing CSV if it exists\n",
    "    existing_df = None\n",
    "    if os.path.exists(csv_path) and start_idx > 0:\n",
    "        existing_df = pd.read_csv(csv_path)\n",
    "        print(f\"Resuming from index {start_idx}, found {len(existing_df)} existing records\")\n",
    "    \n",
    "    # Calculate remaining batches\n",
    "    remaining_df = df.iloc[start_idx:]\n",
    "    n_batches = (len(remaining_df) + batch_size - 1) // batch_size\n",
    "    print(f\"Processing {len(remaining_df)} remaining verses in {n_batches} batches...\")\n",
    "    \n",
    "    try:\n",
    "        # Process each batch\n",
    "        for i in tqdm(range(n_batches)):\n",
    "            batch_start = i * batch_size\n",
    "            batch_end = min((i + 1) * batch_size, len(remaining_df))\n",
    "            batch_df = remaining_df.iloc[batch_start:batch_end].copy()\n",
    "            \n",
    "            # Generate embeddings for batch\n",
    "            batch_embeddings = [\n",
    "                embeddings_model.embed_query(text) \n",
    "                for text in batch_df['text']\n",
    "            ]\n",
    "            batch_df['embedding'] = batch_embeddings\n",
    "            \n",
    "            # Save batch to CSV\n",
    "            if i == 0 and start_idx == 0:\n",
    "                batch_df.to_csv(csv_path, mode='w', header=True, index=False)\n",
    "            else:\n",
    "                batch_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "            \n",
    "            # Update checkpoint\n",
    "            last_processed_idx = start_idx + batch_end\n",
    "            save_checkpoint(checkpoint_file, last_processed_idx, list(completed_books))\n",
    "            \n",
    "            time.sleep(0.1)  # Rate limit delay\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during embedding generation at index {last_processed_idx}: {str(e)}\")\n",
    "        print(f\"Progress saved. Restart the script to continue from index {last_processed_idx}\")\n",
    "        raise\n",
    "    \n",
    "    print(\"Embeddings generation complete!\")\n",
    "    \n",
    "    # ChromaDB Processing\n",
    "    try:\n",
    "        if not os.path.exists(persist_directory):\n",
    "            client = chromadb.PersistentClient(path=persist_directory)\n",
    "            vectorstore = Chroma(\n",
    "                client=client,\n",
    "                embedding_function=embeddings_model,\n",
    "                persist_directory=persist_directory\n",
    "            )\n",
    "        else:\n",
    "            client = chromadb.PersistentClient(path=persist_directory)\n",
    "            vectorstore = Chroma(\n",
    "                client=client,\n",
    "                embedding_function=embeddings_model,\n",
    "                persist_directory=persist_directory\n",
    "            )\n",
    "        \n",
    "        # Process books not yet in ChromaDB\n",
    "        print(\"Adding to ChromaDB...\")\n",
    "        for book in df['book'].unique():\n",
    "            if book in completed_books:\n",
    "                print(f\"Skipping {book} (already processed)\")\n",
    "                continue\n",
    "                \n",
    "            book_df = df[df['book'] == book]\n",
    "            n_book_batches = (len(book_df) + batch_size - 1) // batch_size\n",
    "            \n",
    "            try:\n",
    "                for i in range(n_book_batches):\n",
    "                    start_idx = i * batch_size\n",
    "                    end_idx = min((i + 1) * batch_size, len(book_df))\n",
    "                    batch = book_df.iloc[start_idx:end_idx]\n",
    "                    \n",
    "                    documents = []\n",
    "                    for _, row in batch.iterrows():\n",
    "                        document = Document(\n",
    "                            page_content=row['text'],\n",
    "                            metadata={\n",
    "                                'book': row['book'],\n",
    "                                'chapter': row['chapter'],\n",
    "                                'verse': row['verse']\n",
    "                            }\n",
    "                        )\n",
    "                        documents.append(document)\n",
    "                    \n",
    "                    vectorstore.add_documents(documents)\n",
    "                \n",
    "                completed_books.add(book)\n",
    "                save_checkpoint(checkpoint_file, last_processed_idx, list(completed_books))\n",
    "                print(f\"Added {len(book_df)} verses from {book}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing book {book}: {str(e)}\")\n",
    "                print(f\"Progress saved. Restart the script to continue from book {book}\")\n",
    "                raise\n",
    "        \n",
    "        # Persist the vector store\n",
    "        vectorstore.persist()\n",
    "        \n",
    "        # Clear checkpoint after successful completion\n",
    "        if os.path.exists(checkpoint_file):\n",
    "            os.remove(checkpoint_file)\n",
    "            \n",
    "        print(\"Processing complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during ChromaDB processing: {str(e)}\")\n",
    "        print(\"Embeddings CSV is safe. Restart the script to continue ChromaDB processing.\")\n",
    "        raise\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "process_verses_with_resume(\n",
    "        df=df,\n",
    "        embeddings_model=embeddings_model,\n",
    "        batch_size=100  # Adjust based on your needs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# load csv\\ndf = pd.read_csv('assets/bible/kjv_embeddings.csv')\\n\\n#load chromadb\\nclient = chromadb.PersistentClient(path=persist_directory)\\nvectorstore = Chroma(client=client, embedding_function=embeddings_model, persist_directory=persist_directory)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# load csv\n",
    "df = pd.read_csv('assets/bible/kjv_embeddings.csv')\n",
    "\n",
    "#load chromadb\n",
    "client = chromadb.PersistentClient(path=persist_directory)\n",
    "vectorstore = Chroma(client=client, embedding_function=embeddings_model, persist_directory=persist_directory)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
